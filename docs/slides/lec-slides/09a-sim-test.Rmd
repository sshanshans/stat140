---
title: "Hypothesis testing via simulation"
author: "Dr. Maria Tackett"
date: "03.18.19"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "sta199-slides.css"
    logo: img/sta199-sticker-icon.png
    lib_dir: libs
    nature: 
      highlightLines: true
      highlightStyle: github
      countIncrementalSlides: false
---

layout: true

<div class="my-footer">
<span>
<a href="http://datasciencebox.org" target="_blank">datasciencebox.org</a>
</span>
</div> 

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(broom)
library(knitr)
library(DT)
library(emo)
```

```{r setup, include=FALSE}
# R options
options(
  htmltools.dir.version = FALSE, # for blogdown
  show.signif.stars = FALSE,     # for regression output
  warm = 1
  )
# Set dpi and height for images
opts_chunk$set(fig.height = 2.5, fig.width = 5, dpi = 300) 
# ggplot2 color palette with gray
color_palette <- list(gray = "#999999", 
                      salmon = "#E69F00", 
                      lightblue = "#56B4E9", 
                      green = "#009E73", 
                      yellow = "#F0E442", 
                      darkblue = "#0072B2", 
                      red = "#D55E00", 
                      purple = "#CC79A7")
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
# For magick
dev.off <- function(){
  invisible(grDevices::dev.off())
}
# For ggplot2
ggplot2::theme_set(ggplot2::theme_bw())
```

---

## Announcements

- Lab 08 due Wed, Mar 20 at 11:59p
    - Use 5000 reps for the simulations if having knitting problems with 15000 reps

- HW 04 due Mon, Mar 25 at 11:59p
---

class: center, middle

## Hypothesis testing for a single proportion

---

## Packages

```{r message=FALSE}
library(tidyverse)
library(infer)
```


---

## Organ donors

People providing an organ for donation sometimes seek the help of a special medical 
consultant. These consultants assist the patient in all aspects of the surgery, with 
the goal of reducing the possibility of complications during the medical procedure 
and recovery. Patients might choose a consultant based in part on the historical 
complication rate of the consultant's clients. 

One consultant tried to attract patients by noting that the **average complication rate 
for liver donor surgeries in the US is about 10%, but her clients have only had 3 
complications in the 62 liver donor surgeries she has facilitated**. She claims this is 
strong evidence that her work meaningfully contributes to reducing complications (and 
therefore she should be hired!).

---

## Data

```{r message=FALSE}
organ_donor <- read_csv("data/organ-donor.csv")
organ_donor %>%
  count(outcome)
```

---

## Parameter vs. statistic

A <font class="vocab">parameter</font> for a hypothesis test is the "true" value of interest. We typically 
estimate the parameter using a <font class="vocab">sample statistic</font> as a **point estimate**.

$p~$: true rate of complication

$\hat{p}~$: rate of complication in the sample = $\frac{3}{62}$ = 
`r round(3/62, 3)`

---

## Correlation vs. causation

.question[
Is it possible to assess the consultant's claim using the data?
]

--

No. The claim is that there is a causal connection, but the data are observational.
For example, maybe patients who can afford a medical consultant can afford better
medical care, which can also lead to a lower complication rate.

While it is not possible to assess the causal claim, it is still possible to test 
for an association using these data. For this question we ask, **could the low 
complication rate of $\hat{p}$ = `r round(3/62, 3)` be due to chance?**

---

## Two claims

- <font class="vocab">Null hypothesis</font>: "There is nothing going on"

Complication rate for this consultant is no different than the US average of 10%

--

- <font class="vocab">Alternative hypothesis</font>: "There is something going on"

Complication rate for this consultant is **lower** than the US average of 10%

---

## Hypothesis testing as a court trial

- **Null hypothesis**, $H_0$: Defendant is innocent

- **Alternative hypothesis**, $H_A$: Defendant is guilty

--

- **Present the evidence:** Collect data

--

- **Judge the evidence:** "Could these data plausibly have happened by chance if the null hypothesis were true?"
    * Yes: Fail to reject $H_0$
    * No: Reject $H_0$
    
---

## Hypothesis testing framework

- Start with a null hypothesis, $H_0$, that represents the status quo

- Set an alternative hypothesis, $H_A$, that represents the research question, 
i.e. what weâ€™re testing for

- Conduct a hypothesis test under the assumption that the null hypothesis is true and 
calculate a <font class="vocab">p-value</font> (probability of observed or more extreme outcome given that the 
null hypothesis is true)
    - if the test results suggest that the data do not provide convincing evidence for 
    the alternative hypothesis, stick with the null hypothesis
    - if they do, then reject the null hypothesis in favor of the alternative

---

## Setting the hypotheses

.question[
Which of the following is the correct set of hypotheses?
]

(a) $H_0: p = 0.10$; $H_A: p \ne 0.10$ <br>

(b) $H_0: p = 0.10$; $H_A: p > 0.10$ <br>

(c) $H_0: p = 0.10$; $H_A: p < 0.10$ <br>

(d) $H_0: \hat{p} = 0.10$; $H_A: \hat{p} \ne 0.10$ <br>

(e) $H_0: \hat{p} = 0.10$; $H_A: \hat{p} > 0.10$ <br>

(f) $H_0: \hat{p} = 0.10$; $H_A: \hat{p} < 0.10$ <br>

---

## Simulating the null distribution

Since $H_0: p = 0.10$, we need to simulate a null distribution where the 
probability of success (complication) for each trial (patient) is 0.10.

.question[
Describe how you would simulate the null distribution for this study using a bag of 
chips. How many chips? What colors? What do the colors indicate? How many draws? 
<b>With replacement</b> or <b>without replacement</b>?
]

---

## What do we expect?

.question[
When sampling from the null distribution, what is the expected proportion of success 
(complications)?
]

---

## Simulation #1

```{r echo=FALSE, message=FALSE, warning=FALSE}
# set seed
set.seed(20171011)

# create sample space
outcomes <- c("complication", "no complication")

# draw the first sample of size 62 from the null distribution
sim1 <- sample(outcomes, size = 62, prob = c(0.1, 0.9), replace = TRUE)

# view the sample
table(sim1)

# calculate the simulated sample proportion of complications (red chips)
(p_hat_sim1 <- sum(sim1 == "complication") / length(sim1))

# create an empty data frame
sim_dist <- data.frame(p_hat_sim = rep(NA, 3))

# record the simulated p-hat as the first observation
sim_dist$p_hat_sim[1] <- p_hat_sim1

# plot
ggplot(sim_dist, aes(x = p_hat_sim)) + 
  geom_dotplot() + 
  xlim(0, 0.26) + ylim(0, 10)
```

---

## Simulation #2

```{r message=FALSE, warning=FALSE, echo=FALSE}
sim2 <- sample(outcomes, size = 62, prob = c(0.1, 0.9), replace = TRUE)

table(sim2)

(p_hat_sim2 <- sum(sim2 == "complication") / length(sim2))

sim_dist$p_hat_sim[2] <- p_hat_sim2

ggplot(sim_dist, aes(x = p_hat_sim)) + 
  geom_dotplot() + 
  xlim(0,0.26) + ylim(0,10)
```

---

## Simulation #3


```{r message=FALSE, warning=FALSE, echo=FALSE}
sim3 <- sample(outcomes, size = 62, prob = c(0.1, 0.9), replace = TRUE)

table(sim3)

(p_hat_sim3 <- sum(sim3 == "complication") / length(sim3))

sim_dist$p_hat_sim[3] <- p_hat_sim3

ggplot(sim_dist, aes(x = p_hat_sim)) + 
  geom_dotplot() + 
  xlim(0,0.26) + ylim(0,10)
```

---

## This is getting boring...

We need a way to automate this process!

---

### Using `infer` to generate the null distribution

.small[
```{r}
null_dist <- organ_donor %>%
  specify(response = outcome, success = "complication") %>% 
  hypothesize(null = "point", 
              p = c("complication" = 0.10, "no complication" = 0.90) 
              ) %>% 
  generate(reps = 100, type = "simulate") %>% 
  calculate(stat = "prop")
```
]


---

## Specify

.small[
```{r}
null_dist <- organ_donor %>%
  specify(response = outcome, success = "complication") %>% #<<
  hypothesize(null = "point", 
              p = c("complication" = 0.10, "no complication" = 0.90) 
              ) %>% 
  generate(reps = 100, type = "simulate") %>% 
  calculate(stat = "prop")
```
]

- response: **`outcome`** in the **`organ_donor`** data frame
- success: **`"complication"`**, the level of outcome we're interested in studying

---

## Hypothesize

.small[
```{r}
null_dist <- organ_donor %>%
  specify(response = outcome, success = "complication") %>% 
  hypothesize(null = "point", #<<
              p = c("complication" = 0.10, "no complication" = 0.90) #<<
              ) %>% #<< 
  generate(reps = 100, type = "simulate") %>% 
  calculate(stat = "prop")
```
]

- null: Since we're testing a point null, $H_0: p = 0.10$, we choose **`"point"`**
- State the probability of success, 0.10, and the probability of failure, 0.90 

---

## Generate

.small[
```{r}
null_dist <- organ_donor %>%
  specify(response = outcome, success = "complication") %>% 
  hypothesize(null = "point", 
              p = c("complication" = 0.10, "no complication" = 0.90) 
              ) %>% 
  generate(reps = 100, type = "simulate") %>%  #<<
  calculate(stat = "prop")
```
]

- `reps`: We will generate 100 repetitions here
- `type`: Choose **`"simulate"`** for testing a point null
    - Choose `bootstrap` for estimation (from last class)
    - Choose `permuate` for testing independence (will discuss later)

---

## Calculate

.small[
```{r}
null_dist <- organ_donor %>%
  specify(response = outcome, success = "complication") %>% 
  hypothesize(null = "point", 
              p = c("complication" = 0.10, "no complication" = 0.90) 
              ) %>% 
  generate(reps = 100, type = "simulate") %>%  
  calculate(stat = "prop") #<<
```
]

- Calculate a sample statistic; proportion in this case

---

### Store simulated null distribution

.small[
```{r}
null_dist <- organ_donor %>% #<<
  specify(response = outcome, success = "complication") %>% 
  hypothesize(null = "point", 
              p = c("complication" = 0.10, "no complication" = 0.90) 
              ) %>% 
  generate(reps = 100, type = "simulate") %>%  
  calculate(stat = "prop") 
```
]

```{r echo=FALSE}
null_dist %>% 
  mutate(
    replicate = as.numeric(replicate),
    stat = round(stat, 3)
    )
```

---

## Visualizing the null distribution

.question[
What would you expect the center of the null distribution to be?
]

--

```{r}
ggplot(data = null_dist, mapping = aes(x = stat)) +
  geom_histogram(binwidth = 0.01) +
  labs(title = "Null distribution")
```


---

## Calculating the p-value, visually

.question[
What is the p-value, i.e. in what % of the 
simulations was the simulated sample proportion at least as extreme as the 
observed sample proportion?
]

```{r echo=FALSE}
ggplot(data = null_dist, mapping = aes(x = stat)) +
  geom_histogram(binwidth = 0.01) +
  labs(title = "Null distribution")
```

---

## Calculating the p-value, directly

```{r}
null_dist %>%
  filter(stat <= (3/62)) %>%
  summarise(p_value = n()/nrow(null_dist))
```


---

## Significance level

We often use 5% as the cutoff for whether the p-value is low enough that the data are 
unlikely to have come from the null model. This cutoff value is called the <font class="vocab">significance level, $\alpha$</font>.

- If <font color="red"> p-value < $\alpha$, reject $H_0$</font> in favor of $H_A$: The data provide convincing 
evidence for the alternative hypothesis.

- If <font color="blue">p-value > $\alpha$, fail to reject $H_0$ </font> in favor of $H_A$: The data do not provide 
convincing evidence for the alternative hypothesis.

---

## Conclusion

.question[
What is the conclusion of the hypothesis test?
]

--

Since the p-value is greater than the significance level, we fail to 
reject the null hypothesis. 

These data do not provide convincing evidence that this 
consultant incurs a lower complication rate than 10% (overall US complication rate).

---

## Let's get real

- 100 simulations is not sufficient

- We usually simulate around 15,000 times to get an accurate distribution

---

## Run the test

.small[
```{r cache=TRUE}
null_dist <- organ_donor %>%
  specify(response = outcome, success = "complication") %>%
  hypothesize(null = "point", 
              p = c("complication" = 0.10, "no complication" = 0.90)
              ) %>% 
  generate(reps = 15000, type = "simulate") %>% #<<
  calculate(stat = "prop")
```
]

---

## Visualize and calculate

.small[
```{r fig.height=1.5}
ggplot(data = null_dist, mapping = aes(x = stat)) +
  geom_histogram(binwidth = 0.01) +
  geom_vline(xintercept = 3/62, color = "red")

null_dist %>%
  filter(stat <= 3/62) %>%
  summarise(p_value = n()/nrow(null_dist))
```
]

---

class: center, middle

## One vs. two sided hypothesis tests

---

## Types of alternative hypotheses

- **One sided (one tailed) alternatives**: The parameter is hypothesized to be less 
than or greater than the null value, < or >

--

- **Two sided (two tailed) alternatives**: The parameter is hypothesized to be not 
equal to the null value, $\ne$
    - Calculated as two times the tail area beyond the observed sample statistic
    - More objective, and hence more widely preferred
    
--

.question[
Average systolic blood pressure of people with 
Stage 1 Hypertension is 150 mm Hg. Suppose we want to use a hypothesis test to 
evaluate whether a new blood pressure medication has <b>an effect</b> on the average 
blood pressure of heart patients. What are the hypotheses?
]

---

class: center, middle

## Testing for independence

---

## Is yawning contagious?

.question[
Do you think yawning is contagious?
]

.pull-left[
![empirical](img/09a/yawn1.png)
]
.pull-right[
![empirical](img/09a/yawn2.png)
]

---

## Is yawning contagious?

An experiment conducted by the MythBusters tested if a person can be subconsciously influenced into yawning if another person near them yawns.

[https://www.discovery.com/tv-shows/mythbusters/videos/is-yawning-contagious-2](https://www.discovery.com/tv-shows/mythbusters/videos/is-yawning-contagious-2)

--

.question[
**Do we buy their conclusion?**
]

---

## Study description

In this study 50 people were randomly assigned to two groups: 34 to a group where a person near them yawned (treatment) and 16 to a control group where they didn't see someone yawn (control).

```{r message=FALSE}
mb_yawn <- read_csv("data/mb-yawn.csv")
```

```{r}
mb_yawn %>%
  count(group, outcome)
```

---

## Proportion of yawners

.small[
```{r}
mb_yawn %>%
  count(group, outcome) %>%
  group_by(group) %>%
  mutate(p_hat = n / sum(n))
```
]

- Proportion of yawners in the treatment group: $\frac{10}{34} = 0.2941$
- Proportion of yawners in the control group: $\frac{4}{16} = 0.25$
- Difference: $0.2941 - 0.25 = 0.0441$
- Our results match the ones calculated on the MythBusters episode.

---

## Independence?

.question[
Based on the proportions we calculated, 
do you think yawning is really contagious, i.e. are seeing someone yawn 
and yawning dependent?
]

```{r echo=FALSE}
mb_yawn %>%
  count(group, outcome) %>%
  group_by(group) %>%
  mutate(p_hat = n / sum(n))
```

---

### Dependence, or another possible explanation?

- The observed differences might suggest that yawning is contagious, i.e. seeing someone yawn 
and yawning are dependent.

- But the differences are small enough that we might wonder if they might simple be **due to chance**.

- Perhaps if we were to repeat the experiment, we would see slightly different results.

- So we will do just that - well, somewhat - and see what happens.

- Instead of actually conducting the experiment many times, we will **simulate** our results.

---

## Two competing claims

- "There is nothing going on." 
Yawning and seeing someone yawn are <font class="vocab">independent</font>, yawning is not contagious, observed difference in proportions is simply due to chance. $\rightarrow$ Null hypothesis

- "There is something going on."
Yawning and seeing someone yawn are <font class="vocab">dependent</font>, yawning is contagious, observed difference in proportions is not due to chance. $\rightarrow$ Alternative hypothesis

---

## Simulation setup

1. A regular deck of cards is comprised of 52 cards: 4 aces, 4 of numbers 2-10, 4 jacks, 4 queens, and 4 kings.

2. Take out two aces from the deck of cards and set them aside.
    - Take out Jokers if you have them.

3. The remaining 50 playing cards to represent each participant in the study:
    - 14 face cards (including the 2 aces) represent the people who yawn.
    - 36 non-face cards represent the people who don't yawn.

---

## Running the simulation

1. Shuffle the 50 cards at least 7 times<sup>1</sup> to ensure that the cards counted out are from a random process.

2. Count out the top 16 cards and set them aside. These cards represent the people in the control group.

3. Out of the remaining 34 cards (treatment group) count the <font color="red">number of face cards</font> (the number of people who yawned in the treatment group).

4. Calculate the difference in proportions of yawners (treatment - control). 

5. Input the difference you find in [this form](https://goo.gl/forms/qiBKKJNXB4qjupOw2). 

.footnote[
[1] http://www.dartmouth.edu/~chance/course/topics/winning_number.html
]

