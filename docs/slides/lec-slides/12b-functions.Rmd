---
title: "Functions and automation"
author: "Dr. Maria Tackett"
date: "04.10.19"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "sta199-slides.css"
    logo: img/sta199-sticker-icon.png
    lib_dir: libs
    nature: 
      highlightLines: true
      highlightStyle: github
      countIncrementalSlides: false
---

layout: true

<div class="my-footer">
<span>
<a href="http://datasciencebox.org" target="_blank">datasciencebox.org</a>
</span>
</div> 


```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(broom)
library(knitr)
library(DT)
library(emo)
library(openintro)
library(infer)
library(gridExtra)
```

```{r setup, include=FALSE}
# R options
options(
  htmltools.dir.version = FALSE, # for blogdown
  show.signif.stars = FALSE,     # for regression output
  warm = 1
  )
# Set dpi and height for images
knitr::opts_chunk$set(fig.height = 2.5, fig.width = 5, dpi = 300) 
# ggplot2 color palette with gray
color_palette <- list(gray = "#999999", 
                      salmon = "#E69F00", 
                      lightblue = "#56B4E9", 
                      green = "#009E73", 
                      yellow = "#F0E442", 
                      darkblue = "#0072B2", 
                      red = "#D55E00", 
                      purple = "#CC79A7")
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
# For magick
dev.off <- function(){
  invisible(grDevices::dev.off())
}
# For ggplot2
ggplot2::theme_set(ggplot2::theme_bw())
```

---

## Announcements

- Extra credit due Mon, Apr 15 at 11:59p

- HW 6 due Wed, Apr 17 at 11:59p

- Thursday: 
    - My office hours: 10:30 - 11:30
    - Regular lab

---

## Visualize

.question[
How would you go about creating this visualization: Visualize the average yearly score for movies that made it on the top 250 list over time.
]

--

.small[
```{r echo=FALSE, warning = F, message = F}
library(rvest)

page <- read_html("http://www.imdb.com/chart/top")

titles <- page %>%
  html_nodes(".titleColumn a") %>%
  html_text()

years <- page %>%
  html_nodes(".secondaryInfo") %>%
  html_text() %>%
  str_replace("\\(", "") %>% # remove (
  str_replace("\\)", "") %>% # remove )
  as.numeric()

scores <- page %>%
  html_nodes("#main strong") %>%
  html_text() %>%
  as.numeric()
  
imdb_top_250 <- tibble(
  title = titles, 
  year = years, 
  score = scores
  ) 

imdb_top_250 <- imdb_top_250 %>%
  mutate(rank = 1:250)

imdb_top_250 %>% 
  group_by(year) %>%
  summarise(avg_score = mean(score)) %>%
  ggplot(aes(y = avg_score, x = year)) +
    geom_point() +
    geom_smooth(method = "lm") +
    xlab("year")
```
]
---

## Potential challenges

- Unreliable formatting at the source
- Data broken into many pages
- ...

.question[
Compare the display of information at [raleigh.craigslist.org/search/apa](https://raleigh.craigslist.org/search/apa) to the list on the IMDB top 250 list. 

What challenges can you foresee in scraping a list of the available apartments?
]

---

class: center, middle

# Application exercise

---

## Popular TV shows


Go to RStudio Cloud $\rightarrow$ Web scraping 

1. Scrape the names, scores, and years of the most popular TV shows on IMDB:
http://www.imdb.com/chart/tvmeter

2. Create a data frame called `tvshows` with four variables (rank, name, score, year)

3. Examine each of the first three TV shows to also obtain the genre and runtime.

Time permitting, also try to get the following:
    - How many episodes so far (time permitting)
    - First five plot keywords (time permitting)

Add this information to the `tvshows` data frame you created earlier.

---

class: center, middle

# Functions

---

## Setup

```{r, warning = F, message = F}
library(tidyverse)
library(rvest)

st <- read_html("http://www.imdb.com/title/tt4574334/")
twd <- read_html("http://www.imdb.com/title/tt1520211/")
got <- read_html("http://www.imdb.com/title/tt0944947/")
```


---

## Why functions?

- Automate common tasks in a power powerful and general way than copy-and-pasting:
    - You can give a function an evocative name that makes your code easier to understand.
    - As requirements change, you only need to update code in one place, instead of many.
    - You eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).

--

- Down the line: Improve your reach as a data scientist by writing functions (and packages!) that others use

---

### When should you write a function?

Whenever youâ€™ve copied and pasted a block of code more than twice.

.question[
Do you see any problems in the code below?
]

.small[
```{r eval=FALSE}
st_episode <- st %>%
  html_nodes(".np_right_arrow .bp_sub_heading") %>%
  html_text() %>%
  str_replace(" episodes", "") %>%
  as.numeric()

got_episode <- got %>%
  html_nodes(".np_right_arrow .bp_sub_heading") %>%
  html_text() %>%
  str_replace(" episodes", "") %>%
  as.numeric()

twd_episode <- twd %>%
  html_nodes(".np_right_arrow .bp_sub_heading") %>%
  html_text() %>%
  str_replace(" episodes", "") %>%
  as.numeric()
```
]

---

## Inputs

.question[
How many inputs does the following code have?
]

```{r eval=FALSE}
st_episode <- st %>%
  html_nodes(".np_right_arrow .bp_sub_heading") %>%
  html_text() %>%
  str_replace(" episodes", "") %>%
  as.numeric()
```

---

## Turn your code into a function

1. Pick a short but informative <font class="vocab">name</font>, preferably a verb.

<br>
<br>
<br>
<br>

```{r eval=FALSE}
scrape_episode <- 
  
  
  
  
  
  
```

---

## Turn your code into a function

1. Pick a short but informative **name**, preferably a verb.
2. List inputs, or <font class="vocab">arguments</font>, to the function inside `function`. If we had more the call would look like `function(x, y, z)`.

<br>

```{r eval=FALSE}
scrape_episode <- function(x){
  
  
  
  
  
}  
```

---

## Turn your code into a function

1. Pick a short but informative **name**, preferably a verb.
2. List inputs, or **arguments**, to the function inside `function`. If we had more the call would look like `function(x, y, z)`.
3. Place the <font class="vocab">code</font> you have developed in body of the function, a `{` block that immediately follows `function(...)`.

```{r}
scrape_episode <- function(x){
  x %>%
    html_nodes(".np_right_arrow .bp_sub_heading") %>%
    html_text() %>%
    str_replace(" episodes", "") %>%
    as.numeric()
}
```

--

```{r}
scrape_episode(st)
```

---

### Check your function

[The Walking Dead](https://www.imdb.com/title/tt1520211/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=332cb927-0342-42b3-815c-f9124e84021d&pf_rd_r=AYY90SEXAACVY3XX1A2E&pf_rd_s=center-1&pf_rd_t=15506&pf_rd_i=tvmeter&ref_=chttvm_tt_2)

```{r}
scrape_episode(twd)
```

[Game of Thrones](https://www.imdb.com/title/tt0944947/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=332cb927-0342-42b3-815c-f9124e84021d&pf_rd_r=AYY90SEXAACVY3XX1A2E&pf_rd_s=center-1&pf_rd_t=15506&pf_rd_i=tvmeter&ref_=chttvm_tt_1)

```{r}
scrape_episode(got)
```

---

## Naming functions

> "There are only two hard things in Computer Science: cache invalidation and naming things." - Phil Karlton

--

- Names should be short but clearly evoke what the function does

--

- Names should be verbs, not nouns

--

- Multi-word names should be separated by underscores (`snake_case` as opposed to `camelCase`)

--

- A family of functions should be named similarly (`scrape_title`, `scrape_episode`, `scrape_genre`, etc.)

--

- Avoid overwriting existing (especially widely used) functions

---

## Scraping show info

.small[
```{r}
scrape_show_info <- function(x){

  title <- x %>%
    html_node("h1") %>%
    html_text(trim = TRUE) 

  runtime <- x %>%
    html_node("time") %>%
    html_text() %>% # could use trim = TRUE instead of str_ functions
    str_replace("\\n", "") %>%
    str_trim()
  
  genres <- x %>%
    html_nodes(".txt-block~ .canwrap a") %>%
    html_text() %>%
    str_c(collapse = ", ")
  
  tibble(title = title, runtime = runtime, genres = genres)
}
```
]

---

.small[
```{r}
scrape_show_info(st)
scrape_show_info(twd)
scrape_show_info(got)
```
]

---

.question[
How would you update the following function to use the URL of the page as an argument?
]

.small[
```{r eval=FALSE}
scrape_show_info <- function(x){

  title <- x %>%
    html_node("h1") %>%
    html_text() %>%
    str_trim()

  runtime <- x %>%
    html_node("time") %>%
    html_text() %>%
    str_replace("\\n", "") %>%
    str_trim()
  
  genres <- x %>%
    html_nodes(".txt-block~ .canwrap a") %>%
    html_text() %>%
    str_trim() %>%
    paste(collapse = ", ")
  
  tibble(title = title, runtime = runtime, genres = genres)
}
```
]

---

.small[
```{r}
scrape_show_info <- function(x){
  
{{  y <- read_html(x) }}

  title <- y %>%
    html_node("h1") %>%
    html_text() %>%
    str_trim()

  runtime <- y %>%
    html_node("time") %>%
    html_text() %>%
    str_replace("\\n", "") %>%
    str_trim()

  genres <- y %>%
    html_nodes(".txt-block~ .canwrap a") %>%
    html_text() %>%
    str_trim() %>%
    paste(collapse = ", ")
  
  tibble(title = title, runtime = runtime, genres = genres)
}
```
]

---

## Let's check

.small[
```{r}
st_url <- "http://www.imdb.com/title/tt4574334/"
twd_url <- "http://www.imdb.com/title/tt1520211/"
got_url <- "http://www.imdb.com/title/tt0944947/"
```
]
--
.small[
```{r}
scrape_show_info(st_url)
scrape_show_info(twd_url)
scrape_show_info(got_url)
```
]

---

class: center, middle

# Automation

---

.question[
You now have a function that will scrape the relevant info on shows given its URL. Where can we get a list of URLs of top 100 most popular TV shows on IMDB? Write the code for doing this in your teams.
]

---

```{r}
urls <- read_html("http://www.imdb.com/chart/tvmeter") %>%
  html_nodes(".titleColumn a") %>%
  html_attr("href") %>%
  paste("http://www.imdb.com", ., sep = "")
```

```{r echo=FALSE}
urls
```

---

### Go to each page, scrape show info 

Now we need a way to programatically direct R to each page on the `urls` list and run the `scrape_show_info` function on that page.

.small[
```{r}
scrape_show_info(urls[1])
scrape_show_info(urls[2])
scrape_show_info(urls[3])
```
]

---

class: middle

## Oh no! 

### 1. We're not scraping genre for every TV show!
### 2. We're repeating our code again!

---

## Update genre code

.small[
```{r}
scrape_show_info <- function(x){
  
  y <- read_html(x) 

  title <- y %>%
    html_node("h1") %>%
    html_text() %>%
    str_trim()

  runtime <- y %>%
    html_node("time") %>%
    html_text() %>%
    str_replace("\\n", "") %>%
    str_trim()

  genres <- y %>%
    html_nodes(".see-more.canwrap~ .canwrap a") %>% #<<
    html_text() %>%
    str_trim() %>%
    paste(collapse = ", ")
  
  tibble(title = title, runtime = runtime, genres = genres)
}
```
]

---

### Try again: go to each page, scrape show info 

```{r}
scrape_show_info(urls[1])
scrape_show_info(urls[2])
scrape_show_info(urls[3])
```

--

**... but we're still repeating our code!**
---

## Automation 

- We need a way to programatically repeat the code

- There are two ways to do this: 
    - use a **`for`** loop
    - **`map`**ping with functional programming
    
---

## `for` loops

- **`for`** loops are the simplest and most common type of loop in R
- Iterate through the elements of a vector and evaluate the code block for each

**Goal**: Scrape info from individual pages of TV shows using iteration with for loops. We'll use only 5 shows for now to keep things simple.

---

## `for` loop

### 1) Set up a tibble to store the results

```{r}
n <- 5
top_n_shows <- tibble( title = rep(NA, n), 
                       runtime = rep(NA, n), 
                       genres = rep(NA, n), 
                       epsiodes = rep(NA, n), 
                       keywords = rep(NA, n)
  )
top_n_shows
```

---

## `for` loop

### 2) Iterate through urls to scrape data and save results

```{r}
for(i in 1:n){
  top_n_shows[i, ] = scrape_show_info(urls[i])
}
top_n_shows
```

---

## `map`ping

- **`map`** functions transform the input by applying a function to each element and returning an object the same length as the input

- There are various map functions (e.g. `map_lgl()`, `map_chr()`, `map_dbl()`, `map_df()`)
    - each of which return a different type of object (logical, character, double, and data frame, respectively)

--

- We will `map` the `scrape_show_info` function to each element of `urls`   
    - This will go to each url at a time and get the info
    
**Goal:** Scrape info from individual pages of TV shows using functional programming with mapping. We'll use only 5 shows for now to keep things simple.

---

### `map`: Go to each page, scrape show info 

```{r}
top_n_shows <- map_df(urls[1:n], scrape_show_info)
top_n_shows
```

---

## Slow down the function

- If you get `HTTP Error 429 (Too man requests)` you might want to slow down your hits.

- You can add a `Sys.sleep()` call to slow down your function:

```{r eval=FALSE}
scrape_show_info <- function(x){
#suspend execution between 0 to 1 seconds

  {{  Sys.sleep(runif(1)) }}
  
  ...

}
```
