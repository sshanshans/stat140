---
title: "Lab 02 - Data wrangling and visualization"
subtitle: "What should I major in?"
date: "due Wed, Jan 30 at 11:59p"
output: 
  tufte::tufte_html:
    tufte_variant: "envisioned"
    highlight: pygments
    css: "./sta199-labs.css"
link-citations: yes
---

```{r include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
```

```{marginfigure}
**A note on expectations: ** For each exercise and on your own question you 
answer include any relevant output (tables, summary statistics, plots) in your 
answer. Doing this is easy! Just place any relevant R code in a code chunk, 
and hit Knit HTML.
```

Some define statistics as the field that focuses on turning information into
knowledge. The first step in that process is to summarize and describe the raw
information - the data. In this lab we explore data on college majors and earnings,
specifically the data behind the FiveThirtyEight story ["The Economic Guide To Picking A College Major"](https://fivethirtyeight.com/features/the-economic-guide-to-picking-a-college-major/).

These data originally come from the American Community Survey (ACS) 2010-2012 Public Use 
Microdata Series. While this is outside the scope of this lab, if you are curious about how
raw data from the ACS were cleaned and prepared, see [the code](https://github.com/fivethirtyeight/data/blob/master/college-majors/college-majors-rscript.R) FiveThirtyEight authors used.

We should also note that there are many considerations that go into picking a major.
Earnings potential and employment prospects are two of them, and they are important,
but they don't tell the whole story. Keep this in mind as you analyze the data.


# Getting Started

Each of your assignments will begin with the following steps. You saw these once in class, and they're outlined in detail here again. Going forward each lab will start with a "Getting started" section but details will be a bit more sparse than this. You can always refer back to this lab for a detailed list of the steps involved for getting started with an assignment.

## Clone Assignment Repo

- Go to the STA199-Sp19 organization on GitHub ([https://github.com/STA199-Sp19](https://github.com/STA199-Sp19)). Click on the repo with the prefix **lab-02-**. It contains the starter documents you need to complete the lab.

- Click on the green **Clone or download** button, select **Use HTTPS** (this might already be selected by default, and if it is, you'll see the text **Clone with HTTPS** as in the image below). Click on the clipboard icon to copy the repo URL.

- Go to RStudio Cloud and into the STA 199 course workspace. Create a **New Project from Git Repo**. You will need to click on the down arrow next to the **New Project** button to see this option.

- Copy and paste the URL of your assignment repo into the dialog box.  Be sure "Add packages from the base project" is checked. 

- Click OK, and you should see the contents from your GitHub repo in the Files pane in RStudio. 

## Configure git

Use the `use_git_config()` function from the `usethis` package to configure Git, so RStudio and GitHub can communicate with each other.

Type the following lines of code in the **console** in RStudio filling in your name and email address.

```{marginfigure}
Your email address is the address tied to your GitHub account and your name should be first and last name.
```

```{r eval=FALSE}
library(usethis)
use_git_config(user.name="your name", user.email="your email")
```

Once you run the code, your values for `user.name` and `user.email` will show in the console. If your `user.name` and `user.email` are correct, you're good to go! Otherwise, run the code again with the necessary changes. 

## Project name: 

Currently your project is called *Untitled Project*. Update the name of your project to be "Lab 02 - Data wrangling and visualization".



# Packages

In this lab we will work with the `tidyverse` and `fivethirtyeight` packages. Load the packages into the **console**.

```{r}
library(tidyverse)
library(fivethirtyeight)
```

Note that these packages are also loaded in your R Markdown document.


# Warm up

**Pick one team member to complete the steps in this section while the others contribute to the discussion but do not actually touch the files on their computer.**

Before we introduce the data, let's warm up with some simple exercises.

## YAML: 

Open the R Markdown (Rmd) file in your project, change the author name to your **team** name, and knit the document.

## Commiting and pushing changes:

- Go to the **Git** pane in your RStudio. 
- View the **Diff** and confirm that you are happy with the changes.
- Add a commit message like "Update team name" in the **Commit message** box and hit **Commit**.
- Click on **Push**. This will prompt a dialogue box where you first need to enter your user name, and then your password.

## Pulling changes:

Now, the remaining team members who have not been concurrently making these changes on their projects should click on the **Pull** button in their Git pane and observe that the changes are now reflected on their projects as well.

# Load the data

The data frame we will be working with today is called `college_recent_grads` and it's in the `fivethirtyeight` package.

To find out more about the dataset, type the following in your Console: `?college_recent_grads`. A question mark before the name of an object will always bring up its help file. This command must be ran in the Console.

`college_recent_grads` is a tidy **data frame**, with each row 
representing an **observation** and each column representing a **variable**.

To view the data, click on the name of the data frame in the Environment tab.

You can also take a quick peek at your data frame and view its dimensions 
with the `glimpse` function.

```{r glimpse}
glimpse(college_recent_grads)
```

The description of the variables, i.e. the **codebook**, is given below.

| Header                        |  Description
|:----------------|:--------------------------------
|`rank`                         | Rank by median earnings
|`major_code`                   | Major code, FO1DP in ACS PUMS
|`major`                        | Major description
|`major_category`               | Category of major from Carnevale et al
|`total`                        | Total number of people with major
|`sample_size`                  | Sample size (unweighted) of full-time, year-round ONLY (used for earnings)
|`men`                          | Male graduates
|`women`                        | Female graduates
|`sharewomen`                   | Women as share of total
|`employed`                     | Number employed (ESR == 1 or 2)
|`employed_full_time`           | Employed 35 hours or more
|`employed_part_time`           | Employed less than 35 hours
|`employed_full_time_yearround` | Employed at least 50 weeks (WKW == 1) and at least 35 hours (WKHP >= 35)
|`unemployed`                   | Number unemployed (ESR == 3)
|`unemployment_rate`            | Unemployed / (Unemployed + Employed)
|`median`                       | Median earnings of full-time, year-round workers
|`p25th`                        | 25th percentile of earnings
|`p75th`                        | 75th percentile of earnings
|`college_jobs`                 | Number with job requiring a college degree
|`non_college_jobs`             | Number with job not requiring a college degree
|`low_wage_jobs`                | Number in low-wage service jobs

The `college_recent_grads` data frame is a trove of information. Let's think about 
some questions we might want to answer with these data:

- Which major has the lowest unemployment rate?
- Which major has the highest percentage of women?
- How do the distributions of median income compare across major categories?
- Do women tend to choose majors with lower or higher earnings?

In the next section we aim to answer these questions.

# Data wrangling and visualization

## Which major has the lowest unemployment rate?

In order to answer this question all we need to do is sort the data. We use the
`arrange` function to do this, and sort it by the `unemployment_rate` variable. 
By default `arrange` sorts in ascending order, which is what we want here -- 
we're interested in the major with the *lowest* unemployment rate.

```{r lowest-unemp}
college_recent_grads %>%
  arrange(unemployment_rate)
```

This gives us what we wanted, but not in an ideal form. First, the name of 
the major barely fits on the page. Second, some of the variables are not 
that useful (e.g. `major_code`, `major_category`) and some we might want 
front and center are not easily viewed (e.g. `unemployment_rate`).

We can use the `select` function to choose which variables to display, and 
in which order:

```{marginfigure}
Note how easily we expanded our code with adding another step to our pipeline,
with the pipe operator: `%>%`.
```

```{r lowest-unemp-select}
college_recent_grads %>%
  arrange(unemployment_rate) %>%
  select(rank, major, unemployment_rate)
```

Ok, this is looking better, but do we really need all those decimal places in the 
unemployment variable? Not really!

There are two ways we can address this problem. One would be to round the 
`unemployment_rate` variable in the dataset or we can change the number of digits 
displayed, without touching the input data.

Below are instructions for how you would do both of these:

- Round `unemployment_rate`: We create a new variable with the `mutate` function. 
In this case, we're overwriting the existing `unemployment_rate` variable, by 
`round`ing it to `4` decimal places.

```{r}
college_recent_grads %>%
  arrange(unemployment_rate) %>%
  select(rank, major, unemployment_rate) %>%
  mutate(unemployment_rate = round(unemployment_rate, digits = 4))
```

- Change displayed number of digits without touching data: We can add an option to 
our R Markdown document to change the displayed number of digits in the output. 
To do so, add a new chunk, and set:

```{r}
options(digits = 2)
```

Note that the `digits` in `options` is scientific digits, and in `round` they are 
decimal places. If you're thinking "Wouldn't it be nice if they were 
consistent?", you're right...

You don't need to do both of these, that would be redundant. The next exercise 
asks you to choose one.

1. Which of these options, changing the input data or altering the 
number of digits displayed without touching the input data, is the better option? 
Explain your reasoning. Then, implement the option you chose.

## Which major has the highest percentage of women?

To answer such a question we need to arrange the data in descending order. For 
example, if earlier we were interested in the major with the highest unemployment 
rate, we would use the following:

```{marginfigure}
The `desc` function specifies that we want `unemployment_rate` in descending order.
```

```{r}
college_recent_grads %>%
  arrange(desc(unemployment_rate)) %>%
  select(rank, major, unemployment_rate)
```

2. Using what you've learned so far, arrange the data in descending order with respect to proportion of women in a major, and display only the major,
the total number of people with major, and proportion of women. Show only the 
top 3 majors by adding `head(3)` at the end of the pipeline.

## How do the distributions of median income compare across major categories?

```{marginfigure}
A percentile is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value below which 20% of the observations may be found. (Source: [Wikipedia](https://en.wikipedia.org/wiki/Percentile)
```

There are three types of incomes reported in this data frame: `p25th`, `median`, 
and `p75th`. These correspond to the 25th, 50th, and 75th percentiles of the 
income distribution of sampled individuals for a given major.

3. Why do we often choose the median, rather than the mean, to 
describe the typical income of a group of people?

The question we want to answer "How do the distributions of median income compare across major categories?". We need to do a few things to answer this question: First, we need to group the data by `major_category`. Then, we need a way to summarize the 
distributions of median income within these groups. This decision will depend on the 
shapes of these distributions. So first, we need to visualize the data.

We use the `ggplot` function to do this. The first argument is the data frame, and 
the next argument gives the mapping of the variables of the data to the `aes`thetic 
elements of the plot.

Let's start simple and take a look at the distribution of all median incomes, 
without considering the major categories.

```{r}
ggplot(data = college_recent_grads, mapping = aes(x = median)) +
  geom_histogram()
```

Along with the plot, we get a message:

```
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
```

This is telling us that we might want to reconsider the binwidth we chose for our 
histogram -- or more accurately, the binwidth we didn't specify. It's good practice 
to always thing in the context of the data and try out a few binwidths before 
settling on a binwidth. You might ask yourself: "What would be a meaningful 
difference in median incomes?" $1 is obviously too little, $10000 might be too high.

4. Try binwidths of $1000 and $5000 and choose one. Explain your reasoning for your choice. Note that the binwidth is an argument for the `geom_histogram` function. So to specify a binwidth of $1000, you would use 
`geom_histogram(binwidth = 1000)`.

We can also calculate summary statistics for this distribution using the 
`summarise` function:

```{r}
college_recent_grads %>%
  summarise(min = min(median), max = max(median),
            mean = mean(median), med = median(median),
            sd = sd(median), 
            q1 = quantile(median, probs = 0.25),
            q3 = quantile(median, probs = 0.75))
```

5. Based on the shape of the histogram you created in the 
previous exercise, determine which of these summary statistics is useful 
for describing the distribution. Write up your description (remember 
shape, center, spread, any unusual observations) and include the summary 
statistic output as well.

Next, we facet the plot by major category.

```{r}
ggplot(data = college_recent_grads, mapping = aes(x = median)) +
  geom_histogram() +
  facet_wrap( ~ major_category, ncol = 4)
```

6. Plot the distribution of `median` income using a histogram, 
faceted by `major_category`. Use the `binwidth` you chose in the earlier 
exercise.

Now that we've seen the shapes of the distributions of 
median incomes for each major category, we should have a better idea for 
which summary statistic to use to quantify the typical median income.

7. Which major category has the highest typical (you'll need 
to decide what this means) median income? Use the partial code below, 
filling it in with the appropriate statistic and function. Also note that we 
are looking for the highest statistic, so make sure to arrange in the correct 
direction. 

```{r eval=FALSE}
college_recent_grads %>%
  group_by(major_category) %>%
  summarise(___ = ___(median)) %>%
  arrange(___)
```

8. Which major category is the least popular in this sample? 
To answer this question we use a new function called `count`, which first 
groups the data and then counts the number of observations in each category (see below). Add to the pipeline appropriately to arrange the results so 
that the major with the lowest observations is on top.

```{r}
college_recent_grads %>%
  count(major_category)
```

## All STEM fields aren't the same

One of the sections of the [FiveThirtyEight story](https://fivethirtyeight.com/features/the-economic-guide-to-picking-a-college-major/) is "All STEM fields aren't the same". Let's see if this 
is true.

First, let's create a new vector called `stem_categories` that lists the 
major categories that are considered STEM fields.

```{r}
stem_categories <- c("Biology & Life Science",
                     "Computers & Mathematics",
                     "Engineering",
                     "Physical Sciences")
```

Then, we can use this to create a new variable in our data frame indicating 
whether a major is STEM or not.

```{r}
college_recent_grads <- college_recent_grads %>%
  mutate(major_type = ifelse(major_category %in% stem_categories, "stem", "not stem"))
```

Let's unpack this: with `mutate` we create a new variable called 
`major_type`, which is defined as `"stem"` if the `major_category` is in 
the vector called `stem_categories` we created earlier, and as `"not stem"` 
otherwise.

`%in%` is a **logical operator**. Other logical operators that are commonly 
used are

| Operator                   | Operation
|:----------------|:--------------
|`x < y`                     | less than
| `x > y`                    | greater than
| `x <= y`                   | less than or equal to
| `x >= y`                   | greater than or equal to
| `x != y`                   | not equal to
| `x == y`                   | equal to
| `x %in% y`                 | contains
| <code>x &#124; y</code>    | or
| `x & y`                    | and
| `!x`                       | not

We can use the logical operators to also `filter` our data for STEM majors 
whose median earnings is less than median for all majors' median earnings, 
which we found to be $36,000 earlier.

```{r}
college_recent_grads %>%
  filter(
    major_type == "stem",
    median < 36000
  )
```

9. Which STEM majors have median salaries equal to or less than the median for all majors' median earnings? Your output should only show 
the major name and median, 25th percentile, and 75th percentile earning for 
that major as and should be sorted such that the major with the highest 
median earning is on top.

## What types of majors do women tend to major in?

10. Create a scatterplot of median income vs. proportion of 
women in that major, colored by whether the major is in a STEM field or not. Describe the association between these three variables.


## Writing Task 1

There will be periodic writing exercises this semester to give you an opportunity to practice...

- communicating statistical ideas in writing
- giving and receiving constructive feedback to help refine your writing skills

Each writing exercise will consist of three parts (about 15 minutes each): 

- Respond to a prompt about a statistical concept and/or code 
- Provide constructive feedback for classmates
- Revise your response based on the peer feedback


Go to [https://app.elireview.com](https://app.elireview.com) to complete the first writing exercise. The schedule for this exercise is as follows:

- Response to the prompt - due **Jan 24 at 11:59p**
- Peer review - due **Jan 26 11:59p** (check your email on Friday, Jan 25 for instructions)
- Final draft - due **Jan 28 11:59p** (check your email on Sunday, Jan 27 for instructions)


*If you did not sign up for Eli review in class, follow the [instructions](https://www2.stat.duke.edu/courses/Spring19/sta199.001/slides/lec-slides/2b-tidy-data-wrangle.html#2) to sign up.*

